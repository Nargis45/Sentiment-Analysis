{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed5f85fa",
   "metadata": {},
   "source": [
    "## Channel Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddbb6149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported channel details to youtube_channel_details.csv.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# API details\n",
    "API_KEY = \"YOUR_API_KEY\"\n",
    "CHANNEL_ID = \"UCSaJZiQye_U2ZQXo85bQFLw\"\n",
    "BASE_URL = \"https://www.googleapis.com/youtube/v3/channels\"\n",
    "PART = \"contentDetails,contentOwnerDetails,id,snippet,statistics,status,topicDetails\"\n",
    "\n",
    "# Function to get channel data\n",
    "def get_channel_data(api_key, channel_id):\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"id\": channel_id,\n",
    "        \"part\": PART\n",
    "    }\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# Function to extract relevant data from the API response\n",
    "def extract_channel_info(channel_data):\n",
    "    channel_info = channel_data.get(\"items\", [])[0]  # Assuming only one item in the response\n",
    "    snippet = channel_info.get(\"snippet\", {})\n",
    "    statistics = channel_info.get(\"statistics\", {})\n",
    "    content_details = channel_info.get(\"contentDetails\", {})\n",
    "    content_owner_details = channel_info.get(\"contentOwnerDetails\", {})\n",
    "    status = channel_info.get(\"status\", {})\n",
    "    topic_details = channel_info.get(\"topicDetails\", {})\n",
    "\n",
    "    return {\n",
    "        \"channelId\": channel_info.get(\"id\", \"N/A\"),\n",
    "        \"title\": snippet.get(\"title\", \"N/A\"),\n",
    "        \"description\": snippet.get(\"description\", \"N/A\"),\n",
    "        \"publishedAt\": snippet.get(\"publishedAt\", \"N/A\"),\n",
    "        \"country\": snippet.get(\"country\", \"N/A\"),\n",
    "        \"viewCount\": statistics.get(\"viewCount\", \"N/A\"),\n",
    "        \"subscriberCount\": statistics.get(\"subscriberCount\", \"N/A\"),\n",
    "        \"videoCount\": statistics.get(\"videoCount\", \"N/A\"),\n",
    "        \"hiddenSubscriberCount\": statistics.get(\"hiddenSubscriberCount\", \"N/A\"),\n",
    "        \"uploadsPlaylistId\": content_details.get(\"relatedPlaylists\", {}).get(\"uploads\", \"N/A\"),\n",
    "        \"favoritesPlaylistId\": content_details.get(\"relatedPlaylists\", {}).get(\"favorites\", \"N/A\"),\n",
    "        \"watchLaterPlaylistId\": content_details.get(\"relatedPlaylists\", {}).get(\"watchLater\", \"N/A\"),\n",
    "        \"contentOwnerDetails\": content_owner_details.get(\"contentOwner\", \"N/A\"),\n",
    "        \"status\": status.get(\"privacyStatus\", \"N/A\"),\n",
    "        \"topicDetails\": topic_details.get(\"topicCategories\", \"N/A\")\n",
    "    }\n",
    "\n",
    "# Function to export data to CSV\n",
    "def export_to_csv(data, filename=\"youtube_channel_details.csv\"):\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write headers\n",
    "        writer.writerow([\n",
    "            \"Channel ID\", \"Title\", \"Description\", \"Published At\", \"Country\", \"View Count\", \n",
    "            \"Subscriber Count\", \"Video Count\", \"Hidden Subscriber Count\", \"Uploads Playlist ID\", \n",
    "            \"Favorites Playlist ID\", \"Watch Later Playlist ID\", \"Content Owner\", \"Privacy Status\", \"Topic Categories\"\n",
    "        ])\n",
    "        # Write data rows\n",
    "        writer.writerow([\n",
    "            data[\"channelId\"], data[\"title\"], data[\"description\"], data[\"publishedAt\"], \n",
    "            data[\"country\"], data[\"viewCount\"], data[\"subscriberCount\"], data[\"videoCount\"], \n",
    "            data[\"hiddenSubscriberCount\"], data[\"uploadsPlaylistId\"], data[\"favoritesPlaylistId\"], \n",
    "            data[\"watchLaterPlaylistId\"], data[\"contentOwnerDetails\"], data[\"status\"], data[\"topicDetails\"]\n",
    "        ])\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Get channel data from API\n",
    "    channel_data = get_channel_data(API_KEY, CHANNEL_ID)\n",
    "    # Extract relevant data from the API response\n",
    "    channel_info = extract_channel_info(channel_data)\n",
    "    # Export the data to CSV\n",
    "    export_to_csv(channel_info)\n",
    "    print(f\"Exported channel details to youtube_channel_details.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ccd4a",
   "metadata": {},
   "source": [
    "## Video Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "114c49f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched details for 500 videos.\n",
      "Exported video details to youtube_video_details.csv.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# API details\n",
    "API_KEY = \"YOUR_API_KEY\"\n",
    "CHANNEL_ID = \"UCSaJZiQye_U2ZQXo85bQFLw\"  # Channel ID for Edurise Point\n",
    "BASE_URL_SEARCH = \"https://www.googleapis.com/youtube/v3/search\"\n",
    "BASE_URL_VIDEOS = \"https://www.googleapis.com/youtube/v3/videos\"\n",
    "PART_SNIPPET = \"snippet\"\n",
    "PART_STATISTICS = \"statistics\"\n",
    "PART_CONTENT = \"contentDetails\"\n",
    "TYPE = \"video\"\n",
    "MAX_RESULTS = 50\n",
    "\n",
    "# Function to search videos from the specified channel\n",
    "def search_videos(api_key, channel_id, max_results=50, page_token=None):\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"channelId\": channel_id,\n",
    "        \"type\": TYPE,\n",
    "        \"part\": PART_SNIPPET,\n",
    "        \"maxResults\": max_results,\n",
    "    }\n",
    "    if page_token:\n",
    "        params[\"pageToken\"] = page_token\n",
    "\n",
    "    response = requests.get(BASE_URL_SEARCH, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# Function to get video statistics\n",
    "def get_video_statistics(api_key, video_ids):\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"id\": \",\".join(video_ids),\n",
    "        \"part\": PART_STATISTICS + \",\" + PART_SNIPPET + \",\" + PART_CONTENT,\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL_VIDEOS, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# Gather all video data for the channel\n",
    "def fetch_video_details(api_key, channel_id):\n",
    "    all_video_details = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        # Search for videos from the specified channel\n",
    "        search_data = search_videos(api_key, channel_id, MAX_RESULTS, next_page_token)\n",
    "        video_ids = [item[\"id\"][\"videoId\"] for item in search_data[\"items\"]]\n",
    "\n",
    "        # Get video statistics\n",
    "        video_stats = get_video_statistics(api_key, video_ids)\n",
    "        for video in video_stats[\"items\"]:\n",
    "            snippet = video.get(\"snippet\", {})\n",
    "            statistics = video.get(\"statistics\", {})\n",
    "            content = video.get(\"contentDetails\", {})\n",
    "\n",
    "            details = {\n",
    "                \"videoId\": video.get(\"id\", \"N/A\"),\n",
    "                \"title\": snippet.get(\"title\", \"N/A\"),\n",
    "                \"description\": snippet.get(\"description\", \"N/A\"),\n",
    "                \"publishedAt\": snippet.get(\"publishedAt\", \"N/A\"),\n",
    "                \"channelTitle\": snippet.get(\"channelTitle\", \"N/A\"),\n",
    "                \"tags\": snippet.get(\"tags\", \"N/A\"),\n",
    "                \"viewCount\": statistics.get(\"viewCount\", \"N/A\"),\n",
    "                \"likeCount\": statistics.get(\"likeCount\", \"N/A\"),\n",
    "                \"commentCount\": statistics.get(\"commentCount\", \"N/A\"),\n",
    "                \"duration\": content.get(\"duration\", \"N/A\")\n",
    "            }\n",
    "            all_video_details.append(details)\n",
    "\n",
    "        # Check if there is another page of results\n",
    "        next_page_token = search_data.get(\"nextPageToken\")\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return all_video_details\n",
    "\n",
    "# Export data to CSV\n",
    "def export_to_csv(data, filename=\"youtube_video_details.csv\"):\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write headers\n",
    "        writer.writerow([\"Video ID\", \"Title\", \"Description\", \"Published At\", \"Channel Title\", \"View Count\", \"Like Count\", \"Comment Count\", \"Video Duration\", \"Video Tags\"])\n",
    "        # Write data rows\n",
    "        for item in data:\n",
    "            writer.writerow([item[\"videoId\"], item[\"title\"], item[\"description\"], item[\"publishedAt\"], item[\"channelTitle\"], item[\"viewCount\"], item[\"likeCount\"], item[\"commentCount\"], item[\"duration\"], item[\"tags\"]])\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    video_details = fetch_video_details(API_KEY, CHANNEL_ID)\n",
    "    print(f\"Fetched details for {len(video_details)} videos.\")\n",
    "    export_to_csv(video_details)\n",
    "    print(\"Exported video details to youtube_video_details.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e2e7be",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a21dd8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found playlist: UUSaJZiQye_U2ZQXo85bQFLw\n",
      "Found 105 videos in the playlist.\n",
      "Fetching comments for video EZNeU4G1yNI...\n",
      "Fetching comments for video 6ABBZ8DkPXU...\n",
      "Fetching comments for video xdmzFPxCY6w...\n",
      "Fetching comments for video 8t0dDGhGL9Y...\n",
      "Fetching comments for video edh3-Q1wfio...\n",
      "Fetching comments for video idwhPzZkGBI...\n",
      "Fetching comments for video xC_hIZt8xVU...\n",
      "Fetching comments for video x7sX570aGi8...\n",
      "Fetching comments for video 3ZCw7Cxkfzo...\n",
      "Fetching comments for video qCNdjzK_pL8...\n",
      "Fetching comments for video 5U2NrvCZ3u4...\n",
      "Fetching comments for video 67R1gGF0hfk...\n",
      "Fetching comments for video _dsuJXDi-iI...\n",
      "Fetching comments for video AlMkP3vxxUY...\n",
      "Fetching comments for video Jb5fyREGr-g...\n",
      "Fetching comments for video nPxRmERyvHE...\n",
      "Fetching comments for video ZSxe86t-ZeI...\n",
      "Fetching comments for video 99mcDZIFiP4...\n",
      "Fetching comments for video Uf6UjaMSG5Q...\n",
      "Fetching comments for video n0g4A2-gp08...\n",
      "Fetching comments for video Td4HEuw95zw...\n",
      "Fetching comments for video UlC8X2BOi0s...\n",
      "Fetching comments for video HfEc6uYGoH8...\n",
      "Fetching comments for video LsKNErKQp5s...\n",
      "Fetching comments for video udT63lrfubQ...\n",
      "Fetching comments for video M07vFBMUjio...\n",
      "Fetching comments for video laOmM45-yKM...\n",
      "Fetching comments for video MGjH7hvRe8I...\n",
      "Fetching comments for video EZaW3LykB-k...\n",
      "Fetching comments for video mGJGHUolow4...\n",
      "Fetching comments for video On77z2b4sEU...\n",
      "Fetching comments for video QrGxA_pKvxQ...\n",
      "Fetching comments for video iPEeid84pmQ...\n",
      "Fetching comments for video eIdgx6j5RyI...\n",
      "Fetching comments for video jA9THRG0m5Q...\n",
      "Fetching comments for video O4vbCK65fw0...\n",
      "Fetching comments for video JnbOM8NMezk...\n",
      "Fetching comments for video nBSB0q_aFBs...\n",
      "Fetching comments for video lumQYx6J2HQ...\n",
      "Fetching comments for video oK6837kt8i8...\n",
      "Fetching comments for video 6_HzRxS4lrk...\n",
      "Fetching comments for video UG2DXc0Nhlc...\n",
      "Fetching comments for video FZXf7lTz9O0...\n",
      "Fetching comments for video I2w3Vf_vh_s...\n",
      "Fetching comments for video rfxnDjqzuuk...\n",
      "Fetching comments for video MUdxK5HSjDw...\n",
      "Fetching comments for video FksmGK9oIG8...\n",
      "Fetching comments for video myiOVt1rlKk...\n",
      "Fetching comments for video noMeadKp5AE...\n",
      "Fetching comments for video CsLqhDxC5Wo...\n",
      "Fetching comments for video J0i2OpW8A1c...\n",
      "Fetching comments for video i0OxD5eEECk...\n",
      "Fetching comments for video p9fBY673_Eo...\n",
      "Fetching comments for video Zy4-ZEFNSFU...\n",
      "Fetching comments for video 2qloImixri0...\n",
      "Fetching comments for video vGZrNVPHTEQ...\n",
      "Fetching comments for video f3BWABxsX-I...\n",
      "Fetching comments for video 3M7RCl0sHpo...\n",
      "Fetching comments for video GxJKnqLaIUg...\n",
      "Fetching comments for video zk9IwyzjZ6A...\n",
      "Fetching comments for video lWvTOMS4bz4...\n",
      "Fetching comments for video uzkuGMPqVC8...\n",
      "Fetching comments for video 8O0_ZJ554b8...\n",
      "Fetching comments for video c_vC8hKIOZI...\n",
      "Fetching comments for video 7P660kYV82k...\n",
      "Fetching comments for video yVS0J8TtTfc...\n",
      "Fetching comments for video VzAiOGDMgbI...\n",
      "Fetching comments for video V3idtlUrrh0...\n",
      "Fetching comments for video QJe0IkDFRnM...\n",
      "Fetching comments for video dxon6CMblEM...\n",
      "Fetching comments for video k0yIeSYO_AA...\n",
      "Fetching comments for video J9_y0-_AGVU...\n",
      "Fetching comments for video Xtbl3DPUceA...\n",
      "Fetching comments for video tXvRTCb4EM8...\n",
      "Fetching comments for video r1TJYjK_jpU...\n",
      "Fetching comments for video oWhF7xxkuD0...\n",
      "Fetching comments for video VMc1M6w9yX8...\n",
      "Fetching comments for video ibba0Z6eTmg...\n",
      "Fetching comments for video WYorXZYkpPE...\n",
      "Fetching comments for video SNUsmQje05M...\n",
      "Fetching comments for video eHfqo5YnWGY...\n",
      "Fetching comments for video 5bX8ODiKMCo...\n",
      "Fetching comments for video iummepuQVAY...\n",
      "Fetching comments for video An1VUDFNUIg...\n",
      "Fetching comments for video L7mRcgGBWWs...\n",
      "Fetching comments for video BuvWpYe9ePc...\n",
      "Fetching comments for video XdSD1REPB00...\n",
      "Fetching comments for video ywTFsOt2Mfs...\n",
      "Fetching comments for video wKobNNFZrMI...\n",
      "Fetching comments for video YXvDte2d_ZQ...\n",
      "Fetching comments for video et21nthHBuM...\n",
      "Fetching comments for video JVZ-saTkXxk...\n",
      "Fetching comments for video tpOWWycpJ8s...\n",
      "Fetching comments for video xSKiLw8jd8s...\n",
      "Fetching comments for video REBxyOgOH80...\n",
      "Fetching comments for video M5byKISituE...\n",
      "Fetching comments for video WHHNbVwOU0o...\n",
      "Fetching comments for video _hCvl8fC7cA...\n",
      "Fetching comments for video QvQtdw3LsC0...\n",
      "Fetching comments for video OfAXhbD7exs...\n",
      "Fetching comments for video QDH2qBO-SRU...\n",
      "Fetching comments for video d5X7LWB6vzA...\n",
      "Fetching comments for video oagDFw4pVh0...\n",
      "Fetching comments for video eW5Swrj9-HI...\n",
      "Fetching comments for video 3n6KghdXcnU...\n",
      "Fetched 271 comments in total.\n",
      "Exported comments to youtube_video_comments.csv.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# API details\n",
    "API_KEY = \"YOUR_API_KEY\"\n",
    "CHANNEL_ID = \"UCSaJZiQye_U2ZQXo85bQFLw\"  # Channel ID\n",
    "BASE_URL_VIDEOS = \"https://www.googleapis.com/youtube/v3/playlistItems\"\n",
    "BASE_URL_COMMENTS = \"https://www.googleapis.com/youtube/v3/commentThreads\"\n",
    "BASE_URL_VIDEO_DETAILS = \"https://www.googleapis.com/youtube/v3/videos\"\n",
    "PART = \"snippet,replies\"\n",
    "MAX_RESULTS = 100  # Max comments per request\n",
    "\n",
    "# Function to get the playlist name from the channel\n",
    "def get_playlist_name_from_channel(api_key, channel_id):\n",
    "    playlist_id = \"UU\" + channel_id[2:]  # This is the \"Uploads\" playlist ID\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"playlistId\": playlist_id,\n",
    "        \"part\": \"snippet\",\n",
    "        \"maxResults\": 1,\n",
    "    }\n",
    "    response = requests.get(BASE_URL_VIDEOS, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    if \"items\" in data:\n",
    "        return data[\"items\"][0][\"snippet\"][\"playlistId\"]\n",
    "    return None\n",
    "\n",
    "# Function to get video IDs from the playlist\n",
    "def get_video_ids_from_playlist(api_key, playlist_id):\n",
    "    video_ids = []\n",
    "    next_page_token = None\n",
    "    \n",
    "    while True:\n",
    "        params = {\n",
    "            \"key\": api_key,\n",
    "            \"playlistId\": playlist_id,\n",
    "            \"part\": \"snippet\",\n",
    "            \"maxResults\": MAX_RESULTS,\n",
    "        }\n",
    "        if next_page_token:\n",
    "            params[\"pageToken\"] = next_page_token\n",
    "        \n",
    "        response = requests.get(BASE_URL_VIDEOS, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Collect video IDs from the playlist\n",
    "        video_ids.extend([item[\"snippet\"][\"resourceId\"][\"videoId\"] for item in data[\"items\"]])\n",
    "        \n",
    "        # Get next page token if available\n",
    "        next_page_token = data.get(\"nextPageToken\")\n",
    "        if not next_page_token:\n",
    "            break  # No more pages, exit the loop\n",
    "    \n",
    "    return video_ids\n",
    "\n",
    "# Function to get video details (title) from video ID\n",
    "def get_video_details(api_key, video_id):\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"id\": video_id,\n",
    "        \"part\": \"snippet\",\n",
    "    }\n",
    "    response = requests.get(BASE_URL_VIDEO_DETAILS, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    video_title = data[\"items\"][0][\"snippet\"][\"title\"]\n",
    "    return video_title\n",
    "\n",
    "# Function to get comments for a video\n",
    "def get_video_comments(api_key, video_id, page_token=None):\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"videoId\": video_id,\n",
    "        \"part\": PART,\n",
    "        \"maxResults\": MAX_RESULTS,\n",
    "    }\n",
    "    if page_token:\n",
    "        params[\"pageToken\"] = page_token\n",
    "    \n",
    "    response = requests.get(BASE_URL_COMMENTS, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# Function to fetch all comments for a video\n",
    "def fetch_all_comments_for_video(api_key, video_id, video_title, playlist_name):\n",
    "    all_comments = []\n",
    "    next_page_token = None\n",
    "    \n",
    "    while True:\n",
    "        comments_data = get_video_comments(api_key, video_id, next_page_token)\n",
    "        \n",
    "        for item in comments_data[\"items\"]:\n",
    "            comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "            comment_details = {\n",
    "                \"playlist_name\": playlist_name,  # Store playlist name with the comment\n",
    "                \"video_title\": video_title,      # Store video title with the comment\n",
    "                \"video_id\": video_id,            # Store video ID with the comment\n",
    "                \"author\": comment.get(\"authorDisplayName\", \"N/A\"),\n",
    "                \"comment\": comment.get(\"textDisplay\", \"N/A\"),\n",
    "                \"publishedAt\": comment.get(\"publishedAt\", \"N/A\"),\n",
    "                \"likeCount\": comment.get(\"likeCount\", \"N/A\"),\n",
    "                \"authorChannelUrl\": comment.get(\"authorChannelUrl\", \"N/A\"),\n",
    "            }\n",
    "            all_comments.append(comment_details)\n",
    "        \n",
    "        next_page_token = comments_data.get(\"nextPageToken\")\n",
    "        if not next_page_token:\n",
    "            break  # No more pages of comments\n",
    "    \n",
    "    return all_comments\n",
    "\n",
    "# Function to export comments to CSV\n",
    "def export_comments_to_csv(comments, filename=\"youtube_video_comments.csv\"):\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write headers, including video_id and playlist_name\n",
    "        writer.writerow([\"Playlist Name\", \"Video Title\", \"Video ID\", \"Author\", \"Comment\", \"Published At\", \"Like Count\", \"Author Channel URL\"])\n",
    "        # Write comment data\n",
    "        for comment in comments:\n",
    "            writer.writerow([comment[\"playlist_name\"], comment[\"video_title\"], comment[\"video_id\"], comment[\"author\"], comment[\"comment\"], comment[\"publishedAt\"], comment[\"likeCount\"], comment[\"authorChannelUrl\"]])\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Get the playlist name from the channel\n",
    "    playlist_name = get_playlist_name_from_channel(API_KEY, CHANNEL_ID)\n",
    "    if not playlist_name:\n",
    "        print(\"Error: Playlist name not found.\")\n",
    "    else:\n",
    "        print(f\"Found playlist: {playlist_name}\")\n",
    "\n",
    "    # Step 2: Get all video IDs from the playlist\n",
    "    video_ids = get_video_ids_from_playlist(API_KEY, playlist_name)\n",
    "    print(f\"Found {len(video_ids)} videos in the playlist.\")\n",
    "    \n",
    "    # Step 3: Fetch all comments for each video\n",
    "    all_comments = []\n",
    "    for video_id in video_ids:\n",
    "        print(f\"Fetching comments for video {video_id}...\")\n",
    "        video_title = get_video_details(API_KEY, video_id)  # Get video title\n",
    "        video_comments = fetch_all_comments_for_video(API_KEY, video_id, video_title, playlist_name)\n",
    "        all_comments.extend(video_comments)\n",
    "    \n",
    "    # Step 4: Export all comments to CSV\n",
    "    print(f\"Fetched {len(all_comments)} comments in total.\")\n",
    "    export_comments_to_csv(all_comments)\n",
    "    print(\"Exported comments to youtube_video_comments.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef468d35",
   "metadata": {},
   "source": [
    "## Playlist Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca92364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported playlist details to youtube_playlists_details.csv.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# API details\n",
    "API_KEY = \"YOUR_API_KEY\"\n",
    "CHANNEL_ID = \"UCSaJZiQye_U2ZQXo85bQFLw\"\n",
    "BASE_URL_PLAYLISTS = \"https://www.googleapis.com/youtube/v3/playlists\"\n",
    "BASE_URL_PLAYLIST_ITEMS = \"https://www.googleapis.com/youtube/v3/playlistItems\"\n",
    "BASE_URL_VIDEOS = \"https://www.googleapis.com/youtube/v3/videos\"\n",
    "PART_PLAYLISTS = \"contentDetails,id,localizations,player,snippet,status\"\n",
    "PART_PLAYLIST_ITEMS = \"contentDetails\"\n",
    "PART_VIDEOS = \"statistics\"\n",
    "MAX_RESULTS = 50\n",
    "\n",
    "# Function to get playlists data\n",
    "def get_playlists_data(api_key, channel_id, max_results=50, page_token=None):\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"channelId\": channel_id,\n",
    "        \"part\": PART_PLAYLISTS,\n",
    "        \"maxResults\": max_results,\n",
    "    }\n",
    "    if page_token:\n",
    "        params[\"pageToken\"] = page_token\n",
    "\n",
    "    response = requests.get(BASE_URL_PLAYLISTS, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# Function to get video IDs from a playlist\n",
    "def get_video_ids_from_playlist(api_key, playlist_id, max_results=50, page_token=None):\n",
    "    video_ids = []\n",
    "    while True:\n",
    "        params = {\n",
    "            \"key\": api_key,\n",
    "            \"playlistId\": playlist_id,\n",
    "            \"part\": PART_PLAYLIST_ITEMS,\n",
    "            \"maxResults\": max_results,\n",
    "        }\n",
    "        if page_token:\n",
    "            params[\"pageToken\"] = page_token\n",
    "\n",
    "        response = requests.get(BASE_URL_PLAYLIST_ITEMS, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        video_ids.extend([item[\"contentDetails\"][\"videoId\"] for item in data.get(\"items\", [])])\n",
    "        page_token = data.get(\"nextPageToken\")\n",
    "        if not page_token:\n",
    "            break\n",
    "\n",
    "    return video_ids\n",
    "\n",
    "# Function to get view and like counts for a list of video IDs\n",
    "def get_video_stats(api_key, video_ids):\n",
    "    total_views = 0\n",
    "    total_likes = 0\n",
    "    for i in range(0, len(video_ids), 50):  # API supports up to 50 video IDs per call\n",
    "        params = {\n",
    "            \"key\": api_key,\n",
    "            \"id\": \",\".join(video_ids[i:i + 50]),\n",
    "            \"part\": PART_VIDEOS,\n",
    "        }\n",
    "        response = requests.get(BASE_URL_VIDEOS, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        total_views += sum(int(item[\"statistics\"].get(\"viewCount\", 0)) for item in data.get(\"items\", []))\n",
    "        total_likes += sum(int(item[\"statistics\"].get(\"likeCount\", 0)) for item in data.get(\"items\", []) if \"likeCount\" in item[\"statistics\"])\n",
    "    return total_views, total_likes\n",
    "\n",
    "# Function to extract relevant data from playlist response\n",
    "def extract_playlist_info(api_key, playlists_data):\n",
    "    playlists_info = []\n",
    "\n",
    "    for item in playlists_data.get(\"items\", []):\n",
    "        snippet = item.get(\"snippet\", {})\n",
    "        content_details = item.get(\"contentDetails\", {})\n",
    "        player = item.get(\"player\", {})\n",
    "        status = item.get(\"status\", {})\n",
    "        localizations = item.get(\"localizations\", {})\n",
    "\n",
    "        playlist_id = item.get(\"id\", \"N/A\")\n",
    "        video_ids = get_video_ids_from_playlist(api_key, playlist_id)\n",
    "        total_views, total_likes = get_video_stats(api_key, video_ids)\n",
    "\n",
    "        playlists_info.append({\n",
    "            \"playlistId\": playlist_id,\n",
    "            \"title\": snippet.get(\"title\", \"N/A\"),\n",
    "            \"description\": snippet.get(\"description\", \"N/A\"),\n",
    "            \"publishedAt\": snippet.get(\"publishedAt\", \"N/A\"),\n",
    "            \"channelId\": snippet.get(\"channelId\", \"N/A\"),\n",
    "            \"playlistItemsCount\": content_details.get(\"itemCount\", \"N/A\"),\n",
    "            \"embedHtml\": player.get(\"embedHtml\", \"N/A\"),\n",
    "            \"status\": status.get(\"privacyStatus\", \"N/A\"),\n",
    "            \"localizations\": \", \".join([f\"{key}: {value.get('title', 'N/A')}\" for key, value in localizations.items()]),\n",
    "            \"totalViews\": total_views,  # Add total views\n",
    "            \"totalLikes\": total_likes   # Add total likes\n",
    "        })\n",
    "\n",
    "    return playlists_info\n",
    "\n",
    "# Function to export data to CSV\n",
    "def export_to_csv(data, filename=\"youtube_playlists_details.csv\"):\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write headers\n",
    "        writer.writerow([\n",
    "            \"Playlist ID\", \"Title\", \"Description\", \"Published At\", \"Channel ID\",\n",
    "            \"Playlist Items Count\", \"Embed HTML\", \"Privacy Status\", \"Localizations\", \"Total Views\", \"Total Likes\"\n",
    "        ])\n",
    "        # Write data rows\n",
    "        for item in data:\n",
    "            writer.writerow([\n",
    "                item[\"playlistId\"], item[\"title\"], item[\"description\"], item[\"publishedAt\"],\n",
    "                item[\"channelId\"], item[\"playlistItemsCount\"], item[\"embedHtml\"],\n",
    "                item[\"status\"], item[\"localizations\"], item[\"totalViews\"], item[\"totalLikes\"]\n",
    "            ])\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Get playlists data from API\n",
    "    next_page_token = None\n",
    "    all_playlists_info = []\n",
    "\n",
    "    while True:\n",
    "        playlists_data = get_playlists_data(API_KEY, CHANNEL_ID, MAX_RESULTS, next_page_token)\n",
    "        playlists_info = extract_playlist_info(API_KEY, playlists_data)\n",
    "        all_playlists_info.extend(playlists_info)\n",
    "\n",
    "        # Check if there are more pages to fetch\n",
    "        next_page_token = playlists_data.get(\"nextPageToken\")    \n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    # Export the data to CSV\n",
    "    export_to_csv(all_playlists_info)\n",
    "    print(f\"Exported playlist details to youtube_playlists_details.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b2b4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
